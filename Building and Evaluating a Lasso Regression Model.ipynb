{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing and Evaluating a Lasso Regression Model Applied to Census and Sales Data\n",
    "## By Tyler Chambers\n",
    "### Created for APRD6432: Digital Advertising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project I am constructing a Lasso Regression Model to compare sales data for different areas of the US to Census data for those regions. The hope is to find a handful of strong predictor variables that we can use to improve our market targeting in the future. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing packages for later use\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#importing the csv file, you can find it in my github\n",
    "Filename = 'finalmaster-ratios.csv'\n",
    "#putting the file into a dataframe called fmr\n",
    "fmr = pd.read_csv(Filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Showing Successful Data Split\n",
      "\\-----------------------------\n",
      "     B01001008  B01001009  B01001010  B01001011  B01001012  B01001013  \\\n",
      "521   6.542778   6.569125  20.093794  30.571022  30.860836  29.648886   \n",
      "\n",
      "     B01001014  B01001015  B01001016  B01001017    ...      B19001008  \\\n",
      "521  26.794653  29.815748  34.900673  35.893067    ...      58.186313   \n",
      "\n",
      "     B19001009  B19001010  B19001011   B19001012   B19001013  B19001014  \\\n",
      "521  57.459287  43.694261  98.318147  115.500194  130.355758  77.161691   \n",
      "\n",
      "     B19001015  B19001016  B19001017  \n",
      "521  43.985072  34.751842  26.439511  \n",
      "\n",
      "[1 rows x 182 columns]\n",
      "     B01001008  B01001009  B01001010  B01001011  B01001012  B01001013  \\\n",
      "309   9.023455    9.72758  25.827791  35.673712   35.08201  32.744787   \n",
      "\n",
      "     B01001014  B01001015  B01001016  B01001017    ...      B19001008  \\\n",
      "309  30.756668  36.123405  37.874843  34.283212    ...      50.537432   \n",
      "\n",
      "     B19001009  B19001010  B19001011   B19001012   B19001013  B19001014  \\\n",
      "309  50.537432  47.085104  98.159242  117.770783  133.103178  79.693642   \n",
      "\n",
      "     B19001015  B19001016  B19001017  \n",
      "309  38.381758  29.547861  27.807192  \n",
      "\n",
      "[1 rows x 182 columns]\n",
      "521    1\n",
      "Name: # Purchases, dtype: int64\n",
      "309    1\n",
      "Name: # Purchases, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LassoLarsCV(copy_X=True, cv=10, eps=2.220446049250313e-16, fit_intercept=True,\n",
       "      max_iter=500, max_n_alphas=1000, n_jobs=1, normalize=True,\n",
       "      positive=False, precompute=False, verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First I'm building the list of variable names as vn\n",
    "vn = list(fmr.columns.values)\n",
    "#Next I'm removing the unwanted first 8 values from the list, these variables are not relevant for our predictions\n",
    "vn = vn[8:190]\n",
    "\n",
    "#Next we are making our dataframes/columns of predictor and output variables\n",
    "predictors = fmr[vn]\n",
    "target = fmr['# Purchases']\n",
    "             \n",
    "#Next we are splitting the data into testing and training data sets\n",
    "pred_train, pred_test, tar_train, tar_test = train_test_split(predictors, target, test_size=.3, random_state=123)\n",
    "#Showing that are split worked\n",
    "print('\\nShowing Successful Data Split')\n",
    "print('\\-----------------------------')\n",
    "print(pred_test.head(1))\n",
    "print(pred_train.head(1))\n",
    "print(tar_test.head(1))\n",
    "print(tar_train.head(1))\n",
    "\n",
    "#Setting up our model's Lasso Parameters to model\n",
    "#A CV=10 should make sure that our results are valid\n",
    "model = LassoLarsCV(cv=10, precompute=False)\n",
    "\n",
    "#Attaching our variables to the model using fit\n",
    "model.fit(pred_train, tar_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting and Evaluating the Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B01001014' 0.8557908775529921]\n",
      "['B01001036' 2.505392496591849]\n",
      "['B01001037' 0.8894214357013622]\n",
      "['B01001038' 1.5315839680821497]\n",
      "['B02001005' 0.4125408937426837]\n",
      "['B13014026' 0.4800240326923769]\n",
      "['B13014027' 0.6977454940063235]\n",
      "['B13016001' 874922971.7249781]\n",
      "['B19001017' 1.4834465563617387]\n"
     ]
    }
   ],
   "source": [
    "#Building the coefficient table\n",
    "#The following line creates a dataframe named predictors_model with one column that has \n",
    "#each row representing one of the variables used for prediction.\n",
    "predictors_model=pd.DataFrame(vn)\n",
    "#The following line simply retitles all the columns in the dataframe \n",
    "#(which is currently only one column large) to the title label, \n",
    "#as before it was simply denoted by 0.\n",
    "predictors_model.columns = ['label']\n",
    "#The following line appends a new column to our dataframe titled ‘coeff’ \n",
    "#that is has a value equal to each coefficient calculated from our Lasso Model. \n",
    "#Since both our dataframe and our model are structured the same way, \n",
    "#the coefficients line up with their correct variable label.\n",
    "predictors_model['coeff'] = model.coef_\n",
    "\n",
    "#This for loop is picking out all of the variables in our dataframe that have a coefficient larger than 0,\n",
    "#indicating a significance in prediction in sales, and then printing these values. \n",
    "for index, row in predictors_model.iterrows():\n",
    "    if row['coeff'] > 0:\n",
    "        print(row.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of the Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B01001014: This variable corresponds to Males aged 40 to 44. Therefore, we can conclude that in areas with higher concentrations of Males aged 40 to 44, we would sell more Bobo Bars.\n",
    "\n",
    "b.\tB01001036: This variable corresponds to Females aged 30 to 34. Therefore, we can conclude that in areas with higher concentrations of Females aged 30 to 34, we would sell more Bobo Bars.\n",
    "\n",
    "c.\tB01001037: This variable corresponds to Females aged 35 to 39. Therefore, we can conclude that in areas with higher concentrations of Females aged 35 to 39, we would sell more Bobo Bars.\n",
    "\n",
    "d.\tB01001038: This variable corresponds to Females aged 40 to 44. Therefore, we can conclude that in areas with higher concentrations of Females aged 40 to 44, we would sell more Bobo Bars.\n",
    "\n",
    "e.\tB02001005: This variable corresponds to individuals who identify as being only Asian in race. Therefore, we can conclude that in areas with higher concentrations of individuals with wholly Asian descent we would sell more Bobo Bars. \n",
    "\n",
    "f.\tB13014026: This variable corresponds to women aged 15-50 who have not had a birth in the last 12 months, are not married, and have attained a Bachelors degree. Therefore, we can conclude that in areas with higher concentration of women aged 15-50 who have not had a birth in the last 12 months, are not married, and have attained a Bachelors degree we would sell more Bobo Bars. A more succinct (but less robust) way to say this might be independent adult women with a 4-year college degree seem to enjoy our Bobo bar.\n",
    "\n",
    "g.\tB13014027: This variable corresponds to women aged 15-50 who have not had a birth in the last 12 months, are not married, and have attained a graduate or professional degree.  Therefore, we can conclude that in areas with higher concentration of women aged 15-50 who have not had a birth in the last 12 months, are not married, and have attained a Graduate or professional degree we would sell more Bobo Bars. A more succinct (but less robust) way to say this might be independent adult with a graduate degree or above seem to enjoy our Bobo Bars. \n",
    "\n",
    "h.\tB13016001: This variable is interesting. It is the highest level of a variable that breaks down women into two camps based on whether or not they have had a baby in the last 12 months, and the creates levels for both of those camps based on age ranges. Since this variable is the highest level, it is simply all women aged 15 to 50. Therefore, we can conclude that in areas with higher concentrations of women aged 15-50, we would sell more Bobo bars. \n",
    "\n",
    "i.\tB19001017: This variable corresponds to households with an income of over 200,000 for the year. Thus, we would conclude that in households with an income over 200,000, we would expect to sell more Bobo bars.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clearly most important variable to report would be women aged 15-50, which had an undeniably huge coefficient at 874922971.7249781. Thus, adult women are clearly the strongest base for our product. The next largest coefficient was women aged 30-34, at 2.505392496591849, thus further homing in our market segmentation. Unfortunately, these two predictors obviously overlap with one another, so although they are the best predictors, they might not be the most practically useful. If I were to critically look at these variables, I might consider lumping our 3 women age groups ( 30-34,35-39, and 40-44 ) together into one variable looking at women aged 30-44, and also pulling the next highest predictive variable, household income over 200,000. This would create a more actionable prediction, but certainly makes some assumptions of the data. The safer bet is women aged 15-50, and then women aged 30-34. But the more practical is women aged 30-44, and household income over 200,000. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the Mean Squared Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data MSE\n",
      "22025.312777378716\n",
      "-------------------\n",
      "Testing data MSE\n",
      "41549.12573000182\n"
     ]
    }
   ],
   "source": [
    "train_error = mean_squared_error(tar_train, model.predict(pred_train))\n",
    "print ('Training data MSE')\n",
    "print(train_error)\n",
    "print('-------------------')\n",
    "test_error = mean_squared_error(tar_test, model.predict(pred_test))\n",
    "print ('Testing data MSE')\n",
    "print(test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our training set, I received a MSE of 22025.312777378716. For our Testing set I got a MSE of 41549.12573000182, which is a value that is close to double that of our training set. This is concerning to me, as it says our regression equation fits our training data much better than our testing data, as our testing data has approximately twice as much variation. To me this says that our model might be overfitting our training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the R^2 Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data R-square\n",
      "0.24002827375880997\n",
      "------------------------\n",
      "Testing data R-square\n",
      "0.17587122769388464\n"
     ]
    }
   ],
   "source": [
    "rsquared_train=model.score(pred_train,tar_train)\n",
    "print ('Training data R-square')\n",
    "print(rsquared_train)\n",
    "print('------------------------')\n",
    "rsquared_test=model.score(pred_test,tar_test)\n",
    "print ('Testing data R-square')\n",
    "print(rsquared_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our training set, we are receiving an R-Squared of 0.24002827375880997, which is a good amount larger when compared to our testing set, which had an R-squared of 0.17587122769388464. Again, this points to the fact that our model developed in our testing data may not be generalizable to the larger population, or at the very least, may be overfitted and less powerful. I would say that census data does not seem to be a very good predictor of Bobo bar sales. Even in our testing environment, we were only able to get an R-squared of approximately .24, which means we are only accounting for 24% of variability with this model. And since our model performs much poorer when used on our testing set, I’d have to say this model is not a strong indicator of sales. At the very least, this data set may give us some insights into key populations, like adult women and affluent households, but by itself, it is not a great predictor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the Baseline Sales Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y interecept:\n",
      "22.194697684317433\n"
     ]
    }
   ],
   "source": [
    "print(\"y interecept:\")\n",
    "print(model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our baseline sales, based on our Y-intercept is 22.194697684317433. Thus, in an area devoid of all of our other named coefficients above, we would still expect to sell 22.19 Bobo bars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
